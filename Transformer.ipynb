{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0c7a0233",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d840177a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionEncoder(nn.Module):\n",
    "    def __init__(self, d, max_len):\n",
    "        super().__init__()\n",
    "        self.d = d\n",
    "        pos = torch.zeros(max_len, d)\n",
    "        for seq in range(max_len):\n",
    "            for i in range(0, d, 2):\n",
    "                pos[seq, i] = math.sin(seq / 10000 ** ((2 * i) / self.d))\n",
    "                pos[seq, i+1] = math.cos(seq / 10000 **((2 * (i + 1) / self.d)))\n",
    "        pos = pos.unsqueeze(0)\n",
    "        self.register_buffer('pos', pos)\n",
    "\n",
    "    def forward(self, X):\n",
    "        length = X.size(1)\n",
    "        X = X * math.sqrt(self.d) + self.pos[:, :length]\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8dc3419c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiheadAttention(nn.Module):\n",
    "    def __init__(self, d, dropout, heads):\n",
    "        super().__init__()\n",
    "        self.heads = heads\n",
    "        self.d = d\n",
    "        self.part = d // heads\n",
    "        self.linQ = nn.Linear(d, d)\n",
    "        self.linK = nn.Linear(d, d)\n",
    "        self.linV = nn.Linear(d, d)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.out = nn.Linear(d, d)\n",
    "    \n",
    "    def attention(self, d, Q, K, V, mask):\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(d)\n",
    "        \n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, -1e9)\n",
    "        scores = F.softmax(scores, dim = -1)\n",
    "        \n",
    "        if self.dropout:\n",
    "            scores = self.dropout(scores)\n",
    "        output = torch.matmul(scores, V)\n",
    "        return output\n",
    "\n",
    "    \n",
    "    def forward(self, Q, K, V, mask):\n",
    "        bs = Q.size(0)\n",
    "        part = self.d // self.heads\n",
    "        Q = self.linQ(Q).view(bs, -1, self.heads, part).transpose(1, 2)\n",
    "        K = self.linK(K).view(bs, -1, self.heads, part).transpose(1, 2)\n",
    "        V = self.linV(V).view(bs, -1, self.heads, part).transpose(1, 2)\n",
    "        scores = self.attention(self.d, Q, K, V, mask)\n",
    "        scores = scores.transpose(1, 2).contiguous()\n",
    "        scores = scores.view(bs, -1, self.d)\n",
    "        output = self.out(scores)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c532cf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dropout, d, d_ff):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.lin1 = nn.Linear(d, d_ff)\n",
    "        self.lin2 = nn.Linear(d_ff, d)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        X = self.dropout(F.relu(self.lin1(X)))\n",
    "        X = self.lin2(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f19df2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormLayer(nn.Module):\n",
    "    def __init__(self, d, eps):\n",
    "        super().__init__()\n",
    "        self.alpha = nn.Parameter(torch.ones(d))\n",
    "        self.beta = nn.Parameter(torch.zeros(d))\n",
    "        self.eps = eps\n",
    "    \n",
    "    def forward(self, X):\n",
    "        X = self.alpha * (X - X.mean(dim = -1, keepdim = True)) / (X.std(dim = -1, keepdim = True) + self.eps) + self.beta\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9948fc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d, d_ff, heads, eps, dropout):\n",
    "        super().__init__()\n",
    "        self.d = d\n",
    "        self.dropout = dropout\n",
    "        self.norm1 = NormLayer(d, eps)\n",
    "        self.norm2 = NormLayer(d, eps)\n",
    "        self.attention = MultiheadAttention(d, dropout, heads)\n",
    "        self.ffn = FeedForward(dropout, d, d_ff)\n",
    "        self.drop1 = nn.Dropout(dropout)\n",
    "        self.drop2 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, X, src_mask):\n",
    "        X = self.norm1(X)\n",
    "        X = X + self.drop1(self.attention(X, X, X, src_mask))\n",
    "        X = self.norm2(X)\n",
    "        X = X + self.drop2(self.ffn(X))\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7aec50b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d, d_ff, heads, max_len = 500, eps = 1e-7, N = 8, dropout = 0.1):\n",
    "        super().__init__()\n",
    "        self.pe = PositionEncoder(d, max_len)\n",
    "        self.norm = NormLayer(d, eps)\n",
    "        self.embed = nn.Embedding(vocab_size, d)\n",
    "        self.layers = nn.ModuleList([EncoderLayer(d, d_ff, heads, eps, dropout) for _ in range(N)])\n",
    "\n",
    "    def forward(self, X, src_mask):\n",
    "        X = self.embed(X)\n",
    "        X = self.pe(X)\n",
    "        for layer in self.layers:\n",
    "            X = layer(X, src_mask)\n",
    "        return self.norm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9cf34c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d, heads, dropout, d_ff, eps):\n",
    "        super().__init__()\n",
    "        self.norm1 = NormLayer(d, eps)\n",
    "        self.att1 = MultiheadAttention(d, dropout, heads)\n",
    "        self.drop1 = nn.Dropout(dropout)\n",
    "        self.norm2 = NormLayer(d, eps)\n",
    "        self.att2 = MultiheadAttention(d, dropout, heads)\n",
    "        self.drop2 = nn.Dropout(dropout)\n",
    "        self.norm3 = NormLayer(d, eps)\n",
    "        self.ffn = FeedForward(dropout, d, d_ff)\n",
    "        self.drop3 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, Y, Z, src_mask, trg_mask):\n",
    "        Y = self.norm1(Y)\n",
    "        Y = Y + self.drop1(self.att1(Y, Y, Y, trg_mask))\n",
    "        Y = self.norm2(Y)\n",
    "        Y = Y + self.drop2(self.att2(Y, Z, Z, src_mask))\n",
    "        Y = self.norm3(Y)\n",
    "        Y = Y + self.drop3(self.ffn(Y))\n",
    "        return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "292c6211",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d, heads, dropout, d_ff, max_len, N, eps):\n",
    "        super().__init__()\n",
    "        self.pos = PositionEncoder(d, max_len = 500)\n",
    "        self.embed = nn.Embedding(vocab_size, d)\n",
    "        self.layers = nn.ModuleList([DecoderLayer(d, heads, dropout, d_ff, eps) for _ in range(N)])\n",
    "        self.norm = NormLayer(d, eps)\n",
    "\n",
    "    def forward(self, Y, Z, src_mask, trg_mask):\n",
    "        Y = self.embed(Y)\n",
    "        Y = self.pos(Y)\n",
    "        for layer in self.layers:\n",
    "            Y = layer(Y, Z, src_mask, trg_mask)\n",
    "        return self.norm(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bf8c9269",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, trg_vocab, vocab_size, d, d_ff, heads, max_len , eps, N, dropout):\n",
    "        super().__init__()\n",
    "        self.Encoder = Encoder(vocab_size, d, d_ff, heads, max_len, eps, N, dropout)\n",
    "        self.Decoder = Decoder(vocab_size, d, heads, dropout, d_ff, max_len, N, eps)\n",
    "        self.out = nn.Linear(d, trg_vocab)\n",
    "    \n",
    "    def forward(self, X, Y, src_mask, trg_mask):\n",
    "        Z = self.Encoder(X, src_mask)\n",
    "        out = self.Decoder(Y, Z, src_mask, trg_mask)\n",
    "        out = self.out(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b478f39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "vocab_size = 1000  \n",
    "trg_vocab = 2000   \n",
    "d = 512     \n",
    "d_ff = 2048\n",
    "heads = 8\n",
    "n = 6\n",
    "max_len = 50\n",
    "dropout = 0.1\n",
    "eps = 1e-6\n",
    "batch_size = 32\n",
    "src_len = 40\n",
    "trg_len = 30\n",
    "learning_rate = 1e-4\n",
    "pad_idx = 0          \n",
    "epochs = 20\n",
    "steps_per_epoch = 50  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431585ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(vocab_size, batch_size, src_len, trg_len):\n",
    "\n",
    "    src_data = torch.randint(2, vocab_size, (batch_size, src_len))\n",
    "    trg_data = torch.randint(2, vocab_size, (batch_size, trg_len))\n",
    "    trg_data[:, 0] = 1\n",
    "    trg_data_target = torch.cat([trg_data[:, 1:], torch.full((batch_size, 1), 2)], dim = -1)\n",
    "\n",
    "    src_mask = torch.ones(batch_size, 1, 1, src_len).bool() \n",
    "    trg_mask = torch.tril(torch.ones(trg_len, trg_len)).bool()\n",
    "    trg_mask = trg_mask.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "    return src_data, trg_data, src_mask, trg_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a220a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer, criterion, device, steps, batch_size, src_len, trg_len, vocab_size):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for step in range(steps):\n",
    "        optimizer.zero_grad()\n",
    "        src_data, trg_data, src_mask, trg_mask = data_loader(vocab_size, batch_size, src_len, trg_len)\n",
    "        src_data = src_data.to(device)\n",
    "        trg_data = trg_data.to(device)\n",
    "        src_mask = src_mask.to(device)\n",
    "        trg_mask = trg_mask.to(device)\n",
    "        output = model(src_data, trg_data, src_mask, trg_mask)\n",
    "        dim = output.size(-1)\n",
    "        output = output.reshape(-1, dim)\n",
    "        trg_data = trg_data.reshape(-1)\n",
    "        loss = criterion(output, trg_data)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / steps\n",
    "    print(f\"平均损失: {avg_loss:.4f}\")\n",
    "\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90986d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型运行在 cpu 上。\n",
      "Start\n",
      "\n",
      "Epoch 1/20\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Transformer(\n",
    "    trg_vocab = trg_vocab, vocab_size = vocab_size, d = d, d_ff = d_ff, \n",
    "    heads = heads, max_len = max_len, N = n, eps = eps, dropout = dropout\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = pad_idx)\n",
    "optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "print(f\"模型运行在 {device} 上。\")\n",
    "print(\"Start\")\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    print(f\"\\nEpoch {epoch}/{epochs}\")\n",
    "    train_epoch(\n",
    "        model, optimizer, criterion, device, \n",
    "        steps_per_epoch, batch_size, src_len, trg_len, vocab_size\n",
    "    )\n",
    "\n",
    "print(\"\\nFinish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3411934c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入序列形状 (Encoder Input): torch.Size([1, 15])\n",
      "预测序列形状 (Token IDs): torch.Size([1, 1])\n",
      "预测的 Token ID 序列: [1]\n"
     ]
    }
   ],
   "source": [
    "def greedy_decode(model, src, src_mask, max_len, sos_idx, eos_idx, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        Z = model.Encoder(src, src_mask) \n",
    "    \n",
    "    trg_tokens = torch.full((1, 1), sos_idx, dtype=torch.long, device=device)\n",
    "    \n",
    "\n",
    "    for i in range(max_len - 1): \n",
    "        trg_len = trg_tokens.size(1)\n",
    "        trg_causal_mask_2d = torch.tril(torch.ones(trg_len, trg_len)).bool().to(device)\n",
    "        trg_mask = trg_causal_mask_2d.unsqueeze(0).unsqueeze(0) \n",
    "        with torch.no_grad():\n",
    "            output = model.Decoder(trg_tokens, Z, src_mask, trg_mask)\n",
    "        pred_logits = model.out(output[:, -1, :]) \n",
    "        next_token = torch.argmax(pred_logits, dim=-1, keepdim=True)\n",
    "        if next_token.item() == eos_idx:\n",
    "            break\n",
    "        trg_tokens = torch.cat([trg_tokens, next_token], dim=1)\n",
    "    return trg_tokens\n",
    "\n",
    "src_len_input = 15\n",
    "src_data = torch.randint(3, 1000, (1, src_len_input)).to(device) # [1, L_src]\n",
    "src_mask = torch.ones(1, 1, 1, src_len_input).bool().to(device)\n",
    "\n",
    "predicted_sequence = greedy_decode(\n",
    "    model=model, \n",
    "    src=src_data, \n",
    "    src_mask=src_mask, \n",
    "    max_len=max_len, \n",
    "    sos_idx=1, \n",
    "    eos_idx=2, \n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(f\"输入序列形状 (Encoder Input): {src_data.shape}\")\n",
    "print(f\"预测序列形状 (Token IDs): {predicted_sequence.shape}\")\n",
    "print(f\"预测的 Token ID 序列: {predicted_sequence.squeeze(0).tolist()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
